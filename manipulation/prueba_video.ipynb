{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRUEBA DETECCION DE VEHICULOS EN VIDEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our body classifier\n",
    "car_classifier = cv2.CascadeClassifier(('../dataset/haarcascade_car.xml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate video capture for video file\n",
    "cap = cv2.VideoCapture(\"videos/autovia.mp4\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< cv2.VideoCapture 00000266D0109D10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\luism\\Desktop\\car_detectors_and_classifier\\manipulation\\prueba_video.ipynb Cell 6\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luism/Desktop/car_detectors_and_classifier/manipulation/prueba_video.ipynb#W5sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luism/Desktop/car_detectors_and_classifier/manipulation/prueba_video.ipynb#W5sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39m# Wait for 100 ms (10 FPS)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/luism/Desktop/car_detectors_and_classifier/manipulation/prueba_video.ipynb#W5sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.00001\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luism/Desktop/car_detectors_and_classifier/manipulation/prueba_video.ipynb#W5sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m cap\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luism/Desktop/car_detectors_and_classifier/manipulation/prueba_video.ipynb#W5sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Loop once video is successfully loaded\n",
    "while True:\n",
    "    \n",
    "    # Read first frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:  # Check if frame is successfully read\n",
    "        break\n",
    "        \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "   \n",
    "    # Pass frame to our car classifier\n",
    "    cars = car_classifier.detectMultiScale(gray,scaleFactor=1.05, minNeighbors=5, minSize=(30, 30))\n",
    "    \n",
    "    # Extract bounding boxes for any bodies identified\n",
    "    for (x,y,w,h) in cars:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)\n",
    "        \n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) ==13: #13 is the Enter Key\n",
    "        break\n",
    "    \n",
    "    # Wait for 100 ms (10 FPS)\n",
    "    time.sleep(0.00001)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modificar los FPS para que el video se vea en tiempo real. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load car classifier\n",
    "car_classifier = cv2.CascadeClassifier('../dataset/haarcascade_car.xml')\n",
    "\n",
    "# Load video file\n",
    "cap = cv2.VideoCapture('video_salida.mp4')\n",
    "\n",
    "# Set video FPS to 20\n",
    "cap.set(cv2.CAP_PROP_FPS, 20)\n",
    "\n",
    "# Loop over the frames from the video\n",
    "while cap.isOpened():\n",
    "    # Read the next frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect cars in the frame\n",
    "    cars = car_classifier.detectMultiScale(gray, 1.4, 2)\n",
    "    \n",
    "    # Draw bounding boxes around the cars\n",
    "    for (x,y,w,h) in cars:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    # Wait for user input to move to the next frame\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### guardar una imagen partiendo de un array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "img3 = Image.fromarray(images[\"train\"][\"ale\"][0][y:y+h,x:x+w])\n",
    "img3.save('imagen.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guarda las detecciones en imagenes, que despues las puedes usar de data set para clasificarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Load car classifier\n",
    "car_classifier = cv2.CascadeClassifier('../dataset/cars.xml')\n",
    "\n",
    "# Load video file\n",
    "cap = cv2.VideoCapture('video_salida.mp4')\n",
    "\n",
    "# Set video FPS to 20\n",
    "cap.set(cv2.CAP_PROP_FPS, 15)\n",
    "\n",
    "# Create a directory to store the detected images if it does not exist\n",
    "if not os.path.exists('detecciones'):\n",
    "    os.makedirs('detecciones')\n",
    "x_contador = 0\n",
    "# Loop over the frames from the video\n",
    "while cap.isOpened():\n",
    "    # Read the next frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect cars in the frame\n",
    "    cars = car_classifier.detectMultiScale(gray,scaleFactor=1.05, minNeighbors=5, minSize=(30, 30))\n",
    "    \n",
    "    # Draw bounding boxes around the cars\n",
    "    for (x,y,w,h) in cars:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)\n",
    "        \n",
    "    # Save image of each detected frame\n",
    "    for i, (x,y,w,h) in enumerate(cars):\n",
    "        \n",
    "        # Extract image of the detected car\n",
    "        car_image = frame[y:y+h, x:x+w]\n",
    "\n",
    "        # Save image of the detected car in JPEG format in the 'detecciones' folder\n",
    "        cv2.imwrite(os.path.join('detecciones', f'carro_{x_contador}.jpg'), car_image)\n",
    "        x_contador += 1\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    # Wait for user input to move to the next frame\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambiar el tamaño de los fotogramas de video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "for i in range(1,22):\n",
    "    cap = cv2.VideoCapture(f'videos/mer{i}.mp4')\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    out = cv2.VideoWriter(f'mer{i}_mod.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 30, (720, 960))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_resized = cv2.resize(frame, (720, 960))\n",
    "        out.write(frame_resized)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intentado definir una region de interes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect cars in the lower half of the frame\n",
    "height, width = frame.shape[:2]\n",
    "bottom_half = gray[height//2:, :]\n",
    "cars = car_classifier.detectMultiScale(bottom_half, scaleFactor=1.05, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "# Adjust the detected car coordinates to the full frame\n",
    "for i in range(len(cars)):\n",
    "    x, y, w, h = cars[i]\n",
    "    cars[i] = (x, y+height//2, w, h)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deteccion de vehiculo en área de interes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\luism\\Desktop\\car_detectors_and_classifier\\manipulation\\prueba_video.ipynb Cell 18\u001b[0m in \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luism/Desktop/car_detectors_and_classifier/manipulation/prueba_video.ipynb#X23sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m roi \u001b[39m=\u001b[39m gray[y1:y2,x1:x2]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luism/Desktop/car_detectors_and_classifier/manipulation/prueba_video.ipynb#X23sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m#gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/luism/Desktop/car_detectors_and_classifier/manipulation/prueba_video.ipynb#X23sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m cars \u001b[39m=\u001b[39m car_classifier\u001b[39m.\u001b[39;49mdetectMultiScale(roi, scaleFactor\u001b[39m=\u001b[39;49m\u001b[39m1.05\u001b[39;49m, minNeighbors\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, minSize\u001b[39m=\u001b[39;49m(\u001b[39m50\u001b[39;49m, \u001b[39m50\u001b[39;49m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luism/Desktop/car_detectors_and_classifier/manipulation/prueba_video.ipynb#X23sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m#cars = car_classifier.detectMultiScale(gray, 1.4, 2)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luism/Desktop/car_detectors_and_classifier/manipulation/prueba_video.ipynb#X23sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luism/Desktop/car_detectors_and_classifier/manipulation/prueba_video.ipynb#X23sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# Draw bounding boxes around the cars\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luism/Desktop/car_detectors_and_classifier/manipulation/prueba_video.ipynb#X23sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mfor\u001b[39;00m (x,y,w,h) \u001b[39min\u001b[39;00m cars:\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Load car classifier\n",
    "car_classifier = cv2.CascadeClassifier('../dataset/cars.xml')\n",
    "\n",
    "# Load video file\n",
    "cap = cv2.VideoCapture('mer1_mod.mp4')\n",
    "\n",
    "# Set video FPS to 20\n",
    "cap.set(cv2.CAP_PROP_FPS, 20)\n",
    "\n",
    "# Loop over the frames from the video\n",
    "while cap.isOpened():\n",
    "    # Read the next frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect cars in the frame\n",
    "    # Define las coordenadas del ROI\n",
    "    x1, y1 = 100, 550\n",
    "    x2, y2 = 720, 650\n",
    "\n",
    "    # Dibuja un rectángulo sobre la imagen original\n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, ), 2)\n",
    "\n",
    "    roi = gray[y1:y2,x1:x2]\n",
    "    #gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    cars = car_classifier.detectMultiScale(roi, scaleFactor=1.05, minNeighbors=5, minSize=(50, 50))\n",
    "\n",
    "    #cars = car_classifier.detectMultiScale(gray, 1.4, 2)\n",
    "    \n",
    "    # Draw bounding boxes around the cars\n",
    "    for (x,y,w,h) in cars:\n",
    "        cv2.rectangle(frame, (x+x1, y+y1), (x+x1+w, y+y1+h), (0, 255, 255), 2)\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    # Wait for user input to move to the next frame\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deteccion de vehiculo en área de interes y etiqueta generica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load car classifier\n",
    "car_classifier = cv2.CascadeClassifier('../datasets/cars.xml')\n",
    "\n",
    "# Load video file\n",
    "cap = cv2.VideoCapture('mer1_mod.mp4')\n",
    "\n",
    "# Set video FPS to 20\n",
    "cap.set(cv2.CAP_PROP_FPS, 20)\n",
    "\n",
    "# Loop over the frames from the video\n",
    "while cap.isOpened():\n",
    "    # Read the next frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect cars in the frame\n",
    "    # Define las coordenadas del ROI\n",
    "    x1, y1 = 100, 550\n",
    "    x2, y2 = 720, 650\n",
    "\n",
    "    # Dibuja un rectángulo sobre la imagen original\n",
    " \n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, ), 2)\n",
    "    roi = gray[y1:y2,x1:x2]\n",
    "    #gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    cars = car_classifier.detectMultiScale(roi, scaleFactor=1.05, minNeighbors=5, minSize=(50, 50))\n",
    "\n",
    "    #cars = car_classifier.detectMultiScale(gray, 1.4, 2)\n",
    "    \n",
    "    # Draw bounding boxes around the cars\n",
    "    \n",
    "    \n",
    "    for (x,y,w,h) in cars:\n",
    "        texto = \"Prueba\"\n",
    "        posicion_etiqueta = (x + x1, y + y1 - 10)\n",
    "        cv2.rectangle(frame, (x+x1, y+y1), (x+x1+w, y+y1+h), (0, 255, 255), 2)\n",
    "        cv2.putText(frame, texto, posicion_etiqueta, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    # Wait for user input to move to the next frame\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deteccion de vehiculo en área de interes y guardado de imagen en format jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "# Load car classifier\n",
    "car_classifier = cv2.CascadeClassifier('../datasets/cars.xml')\n",
    "\n",
    "# Load video file\n",
    "cap = cv2.VideoCapture('videos/autovia2.mp4')\n",
    "\n",
    "# Set video FPS to 20\n",
    "cap.set(cv2.CAP_PROP_FPS,1)\n",
    "#count for enuerate the image\n",
    "# Loop over the frames from the video\n",
    "while cap.isOpened():\n",
    "    # Read the next frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect cars in the frame\n",
    "    # Define las coordenadas del ROI\n",
    "    x1, y1 = 0, 0\n",
    "    x2, y2 = 720, 960\n",
    "\n",
    "    # Dibuja un rectángulo sobre la imagen original\n",
    "    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, ), 2)\n",
    "\n",
    "    roi = gray[y1:y2,x1:x2]\n",
    "    #gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    cars = car_classifier.detectMultiScale(roi, scaleFactor=1.05, minNeighbors=5, minSize=(50, 50))\n",
    "    \n",
    "    \n",
    "    # Save image of each detected frame\n",
    "    for i, (x,y,w,h) in enumerate(cars):\n",
    "        x += x1\n",
    "        y += y1\n",
    "      \n",
    "        # Extract image of the detected car\n",
    "        car_image = frame[y:y+h, x:x+w]\n",
    "        x_contador = random.randint(0, 10000)\n",
    "        # Save image of the detected car in JPEG format in the 'detecciones' folder\n",
    "        if  car_image.shape >=(50,50,3):\n",
    "            cv2.imwrite(os.path.join('detecciones', f'vehicle_{x_contador}.jpg'), car_image)\n",
    "            x_contador += 1\n",
    "\n",
    "    # Draw bounding boxes around the cars\n",
    "    for (x,y,w,h) in cars:\n",
    "        cv2.rectangle(frame, (x+x1, y+y1), (x+x1+w, y+y1+h), (0, 255, 255), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    # Wait for user input to move to the next frame\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_image.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
